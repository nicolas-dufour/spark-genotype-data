import sys
from pyspark import SparkContext
from pyspark.sql import SQLContext
import csv

sc=SparkContext()
spark = SparkSession.builder.getOrCreate()
def listEntries(codon,plant):
	if('.csv' in codon):
		with open('file.csv', 'rb') as f:
		    reader = csv.reader(f)
		    codons = list(reader)
	else:
		codons=[codon]
	if('.csv' in plant):
		with open('file.csv', 'rb') as f:
		    reader = csv.reader(f)
		    plants = list(reader)
	else:
		plants=[plant]
	return(codons,plants)
def prepareQuery(codons,plants): # SELECT codons FROM file WHERE plant=plant1 OR plant=plant2 etc...
	if(codons!=['*']):
		selectstring="plant"
		for i in range(len(codons)):
			selectstring+=', '+codons[i]
	else
		selectstring="*"
	if(plants!=['*']):
		wherestring=""
		for i in range(len(plants)-1):
			wherestring+="plant="+plants[i]+ " or "
		wherestring+="plant="+plants[-1]
	return("SELECT "+codons+" FROM db WHERE "+wherestring)
def dbQuery(dbPath,codon,plant):
	df=sqlContext.read.parquet(dbPath)
	df.createTempView('db')
	codons,plants=listEntries(codon,plant)
	query=prepareQuery(codons,plants)
	spark.sql(query).show()
if __name__ == '__main__':
	dbQuery(sys.argv[1],sys.argv[2],sys.argv[3])





